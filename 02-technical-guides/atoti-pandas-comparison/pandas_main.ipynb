{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185133c0-4134-4b37-90f5-b8447bf55a17",
   "metadata": {},
   "source": [
    "# Atoti vs pandas comparative analysis for Value at Risk: pandas notebook\n",
    "\n",
    "Last tested version: <img src=\"https://img.shields.io/badge/Atoti-v0.8.14-blue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb36613-6d8b-40c3-b9aa-6e15a47c17f6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Aiming to compare the advanced analytics capabilities of Atoti with that of pandas, we will build a notebook that implements, **using pandas**, the main components of a VaR use case:\n",
    "\n",
    "* Compute VaR and ES:\n",
    "    * At two different confidence levels: 95% and 99%; \n",
    "    * At three different granularities: top-of-house (global value for entire financial institution), combination of book and trade, and combination of all attributes.\n",
    "* Track, for each of those queries, the:\n",
    "    * Response time;\n",
    "    * Memory usage.\n",
    "\n",
    "\n",
    "We will also enrich the use case by:\n",
    "* Computing the marginal VaR\n",
    "* Performing simulations\n",
    "\n",
    "ðŸ’¡ **Note:** This notebook uses a dataset of ~5.5GB, which may take a number of minutes to initially load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec769be3-8cc7-49ea-bb1a-21f2d918263b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=atoti-pandas-comparison\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/Discover-Atoti-now.png\" alt=\"Try Atoti\"></a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f0858-c098-48e6-a89d-969a6de7ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install memory_profiler\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215a15d-9ef6-4b2e-8b1b-80e5c9e8d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f11d63-98c6-4daf-99be-47bd8b4f0c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Package Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edacbc-88e5-4070-a273-f3f611525f64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55785be6-2ed4-45a0-a1e3-1d69c3ee99c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trade PnL Table\n",
    "\n",
    "Our trade table is the main table that contains all the trades, some of their attributes, and, most importantly, their Profit-and-Loss (PnL) vectors.\n",
    "\n",
    "We will define the structure of the table, then feed it from out S3 repository. This will be a rather large dataset, which will allow us to perform our comparative analysis at a significant level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea43461-0d49-46bc-8deb-2bf5ec3135f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem()\n",
    "trades=pd.read_parquet(\"bd-connect-london-hybrid-demo-202306/data/pnl/\", filesystem=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db240546-3f50-4bf1-9a4f-2571398d50df",
   "metadata": {},
   "source": [
    "### Book Table\n",
    "\n",
    "The book table will enrich the data model with information about the books that contain our trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebc6e8-e795-41d0-b018-895cfeb992ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"./data/books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a32c6-af7d-411e-89b2-6a3b7a7fe58c",
   "metadata": {},
   "source": [
    "## Merge Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75786ddb-f355-4844-9017-2f4e598d369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=trades.merge(books, how='left',  on=\"BOOKID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f28f20-8cac-4b0e-b577-74978c097035",
   "metadata": {},
   "source": [
    "# Computing the VaR Metrics\n",
    "\n",
    "Since pandas doesn't inherently meanage dynamic aggregation, a pre-aggregation step necessarily needs to be coded for each desired level of aggregation before the statistical/mathematical function is applied to get the final metric.\n",
    "\n",
    "The groupby() function is thus used to perform that initial aggregation of the PnL Vectors, and then the quantile/mean functions would be applied on the resulting set.\n",
    "\n",
    "The downside of this is that each level of aggregation would require its own, multi-line code block, wich introduces **inefficiencies** and **redundancy**. \n",
    "In Atoti, however, a measure is configured only once, with one line of code, and can be subsequently used and evaluated at any granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba5798-13f8-4188-833b-e4d2fce66556",
   "metadata": {},
   "source": [
    "### Computing Top of House VaR and ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa88413-b24a-41ff-9a1b-2704ee29323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRTopOfHouse=merged.groupby(['ASOFDATE'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRTopOfHouse['VaR95']=VaRTopOfHouse.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRTopOfHouse['VaR99']=VaRTopOfHouse.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRTopOfHouse['ES95']=VaRTopOfHouse.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRTopOfHouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedff19-6894-4bf2-a88c-f82f88d057a2",
   "metadata": {},
   "source": [
    "### Computing VaR and ES at BookId and TradeId Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cc727-81b5-4eb9-a672-76b1473bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRByBookandTrade=merged.groupby(['ASOFDATE', 'BOOK', 'TRADEID'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRByBookandTrade['VaR95']=VaRByBookandTrade.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRByBookandTrade['VaR99']=VaRByBookandTrade.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRByBookandTrade['ES95']=VaRByBookandTrade.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRByBookandTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be341a88-b03a-4836-b48f-c4c9be918a46",
   "metadata": {},
   "source": [
    "### Computing VaR and ES at the most granular level (combination of all available qualitative hierarchies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96c741-b5f7-4908-8708-f30e0089c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRGranular=merged.groupby(['ASOFDATE', 'BUSINESS_UNIT', 'SUB_BUSINESS_UNIT', 'TRADING_DESK' , 'BOOKID', 'RISKCLASS', 'TRADEID'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRGranular['VaR95']=VaRGranular.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRGranular['VaR99']=VaRGranular.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRGranular['ES95']=VaRGranular.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRGranular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aead86b-7e56-4ff3-a40f-34214e10db20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Incremental VaR (Parent VAR - Parent VAR excluding self)\n",
    "\n",
    "Since pandas does not have any semantic dimension attached to its columns, it lacks the understanding of any potential hierarchical/order relationships that may lie within them, which means that implementing a measure such as incremental VaR would require us to hard code every step of that logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b34ac-64cd-4865-b361-8ff012fc7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "bookpnl=merged.groupby(['BOOK'])['PNL_VECTOR'].sum().reset_index()\n",
    "deskpnl=merged.groupby(['TRADING_DESK'])['PNL_VECTOR'].sum().reset_index()\n",
    "deskandbook=merged[['TRADING_DESK', 'BOOK']].drop_duplicates().sort_values(by=['TRADING_DESK', 'BOOK']).reset_index(drop=True)\n",
    "\n",
    "deskandbook['DESKPNL']=''\n",
    "deskandbook['BOOKPNL']=''\n",
    "\n",
    "for i in range(len(deskandbook)):\n",
    "    book=deskandbook.loc[i, 'BOOK']\n",
    "    desk=deskandbook.loc[i, 'TRADING_DESK']\n",
    "    bookpl=bookpnl[bookpnl['BOOK']==book]['PNL_VECTOR']\n",
    "    deskpl=deskpnl[deskpnl['TRADING_DESK']==desk]['PNL_VECTOR']\n",
    "    deskandbook.at[i, 'BOOKPNL']=bookpl.values\n",
    "    deskandbook.at[i, 'DESKPNL']=deskpl.values\n",
    "    \n",
    "deskandbook['DESKWITHOUTBOOK']=deskandbook['DESKPNL']-deskandbook['BOOKPNL']\n",
    "deskandbook['VaRDesk95']=deskandbook.apply(lambda x:  np.quantile(np.quantile(x['DESKPNL'], 0.05), 0.05), axis=1)\n",
    "deskandbook['VaRDeskWITHOUTBOOK95']=deskandbook.apply(lambda x: np.quantile(x['DESKWITHOUTBOOK'], 0.05), axis=1)\n",
    "\n",
    "deskandbook['IncrementalVaR']=deskandbook['VaRDesk95']-deskandbook['VaRDeskWITHOUTBOOK95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053b068-5bc3-4281-9034-746a26cd0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskandbook[['TRADING_DESK', 'BOOK', 'IncrementalVaR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b388be4-f93d-4693-a399-73eefe236ec5",
   "metadata": {},
   "source": [
    "# What If Scenarios\n",
    "\n",
    "pandas does not support branching either, which means that the only way to create something similar to a simulation or new scenario would require loading a full new dataset in a separate data structure, not only the deltas (differing data points). This doubles the memory footprint and limits any possibility of contained, side-by-side analytics.\n",
    "\n",
    "e will start by making a copy of the original dataset, then enriching it with the stressed data points, then dropping the duplicates manually to remove the old, unstressed records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d771dc-6b14-4632-96d9-b02a63baa23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed=merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854302a6-0b3f-496f-ba00-7026e91346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition=pd.read_parquet(\"bd-connect-london-hybrid-demo-202306/data/simulation/pnl_16.parquet\", filesystem=s3)\n",
    "stressed=pd.concat([stressed, addition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0815f1-791c-4f5f-bea2-a3b1efb8670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed.drop_duplicates(['BOOKID',\t'ASOFDATE',\t'TRADEID',\t'DATASET',\t'RISKFACTOR',\t'RISKCLASS'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19084d-5aa8-41c8-81af-01c647489502",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=atoti-pandas-comparison\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/Your-turn-to-try-Atoti.jpg\" alt=\"Try Atoti\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
