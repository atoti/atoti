{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185133c0-4134-4b37-90f5-b8447bf55a17",
   "metadata": {},
   "source": [
    "# Atoti vs pandas Comparative Analysis for Value at Risk: pandas Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb36613-6d8b-40c3-b9aa-6e15a47c17f6",
   "metadata": {},
   "source": [
    "To compare the advanced analytics capabilities of Atoti with that of pandas, we will build a notebook that implements, **using pandas**, the main components of a VaR use case:\n",
    "\n",
    "* Compute VaR and ES:\n",
    "    * At two different confidence levels: 95% and 99%\n",
    "    * At three different granularities: top-of-house (global value for entire financial institution), combination of book and trade, and combination of all attributes\n",
    "* Track, for each of those queries, the:\n",
    "    * Response time\n",
    "    * Memory usage\n",
    "* We will also enrich the use case by:\n",
    "    * Computing the marginal VaR\n",
    "    * Performing simulations\n",
    "\n",
    "ðŸ’¡ **Note:** This notebook downloads a dataset of ~5.5GB from Amazon S3, which may take some time to initially load depending on internet speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec769be3-8cc7-49ea-bb1a-21f2d918263b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=atoti-pandas-comparison\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/Discover-Atoti-now.png\" alt=\"Try Atoti\"></a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e215a15d-9ef6-4b2e-8b1b-80e5c9e8d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f11d63-98c6-4daf-99be-47bd8b4f0c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edacbc-88e5-4070-a273-f3f611525f64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55785be6-2ed4-45a0-a1e3-1d69c3ee99c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trade PnL Table\n",
    "\n",
    "Our trade table is the main table that contains all trades, attributes, and most importantly, the Profit-and-Loss (PnL) vectors.\n",
    "\n",
    "We will define the structure of the table, then feed it from our S3 repository. This will be a rather large dataset, which will allow us to perform our comparative analysis at a significant level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea43461-0d49-46bc-8deb-2bf5ec3135f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 / 31 files |â–ˆ-------------------------------------------------| 3.2% Complete"
     ]
    }
   ],
   "source": [
    "# Use anonymous access with s3fs (required for accessing a public S3 bucket)\n",
    "s3fs.S3FileSystem.read_timeout = 1200\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "objects = s3.ls(\"s3://data.atoti.io/notebooks/atoti-pandas-comparison/data/pnl\")\n",
    "\n",
    "# Get total number of files for progress bar calculation and initialize counter\n",
    "total_files = sum(1 for obj in objects if obj.endswith(\".parquet\"))\n",
    "file_count = 1\n",
    "\n",
    "# Iterate over files in the S3 bucket and display the progress bar\n",
    "dataframes = []\n",
    "for obj in objects:\n",
    "    file = f\"s3://{obj}\"\n",
    "    if file != \"s3://data.atoti.io/notebooks/atoti-pandas-comparison/data/pnl/\":\n",
    "        progress_bar.print_progress_bar(\n",
    "            file_count,\n",
    "            total_files,\n",
    "            prefix=f\"Loading {file_count} / {total_files} files\",\n",
    "            suffix=\"Complete\",\n",
    "            length=50,\n",
    "        )\n",
    "        temp_df = pd.read_parquet(file, filesystem=s3)\n",
    "        dataframes.append(temp_df)\n",
    "        file_count += 1\n",
    "\n",
    "trades = pd.concat(dataframes, ignore_index=True)\n",
    "trades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db240546-3f50-4bf1-9a4f-2571398d50df",
   "metadata": {},
   "source": [
    "### Book table\n",
    "\n",
    "The book table will enrich the data model with information about the books that contain our trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebc6e8-e795-41d0-b018-895cfeb992ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\n",
    "    \"s3://data.atoti.io/notebooks/atoti-pandas-comparison/data/books.csv\"\n",
    ")\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a32c6-af7d-411e-89b2-6a3b7a7fe58c",
   "metadata": {},
   "source": [
    "### Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75786ddb-f355-4844-9017-2f4e598d369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = trades.merge(books, how=\"left\", on=\"BOOKID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f28f20-8cac-4b0e-b577-74978c097035",
   "metadata": {},
   "source": [
    "## Computing the VaR Metrics\n",
    "\n",
    "Since pandas doesn't inherently manage dynamic aggregation, a pre-aggregation step necessarily needs to be coded for each desired level of aggregation before the statistical/mathematical function is applied to get the final metric.\n",
    "\n",
    "The `groupby()` function is thus used to perform the initial aggregation of the PnL Vectors, and then the quantile/mean functions would be applied on the resulting set.\n",
    "\n",
    "The downside of this is that each level of aggregation would require its own, multi-line code block, wich introduces **inefficiencies** and **redundancy**. \n",
    "In Atoti, however, a measure is configured only once, with one line of code, and can be subsequently used and evaluated at any granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba5798-13f8-4188-833b-e4d2fce66556",
   "metadata": {},
   "source": [
    "### Computing Top of House VaR and ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa88413-b24a-41ff-9a1b-2704ee29323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRTopOfHouse=merged.groupby(['ASOFDATE'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRTopOfHouse['VaR95']=VaRTopOfHouse.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRTopOfHouse['VaR99']=VaRTopOfHouse.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRTopOfHouse['ES95']=VaRTopOfHouse.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRTopOfHouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedff19-6894-4bf2-a88c-f82f88d057a2",
   "metadata": {},
   "source": [
    "### Computing VaR and ES at BookId and TradeId Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cc727-81b5-4eb9-a672-76b1473bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRByBookandTrade=merged.groupby(['ASOFDATE', 'BOOK', 'TRADEID'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRByBookandTrade['VaR95']=VaRByBookandTrade.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRByBookandTrade['VaR99']=VaRByBookandTrade.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRByBookandTrade['ES95']=VaRByBookandTrade.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRByBookandTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be341a88-b03a-4836-b48f-c4c9be918a46",
   "metadata": {},
   "source": [
    "### Computing VaR and ES at the most granular level (combination of all available qualitative hierarchies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96c741-b5f7-4908-8708-f30e0089c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "VaRGranular=merged.groupby(['ASOFDATE', 'BUSINESS_UNIT', 'SUB_BUSINESS_UNIT', 'TRADING_DESK' , 'BOOKID', 'RISKCLASS', 'TRADEID'])['PNL_VECTOR'].sum().reset_index()\n",
    "VaRGranular['VaR95']=VaRGranular.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.05), axis=1)\n",
    "VaRGranular['VaR99']=VaRGranular.apply(lambda x: np.quantile(x['PNL_VECTOR'], 0.01), axis=1)\n",
    "VaRGranular['ES95']=VaRGranular.apply(lambda x: np.mean(sorted(x['PNL_VECTOR'][:12])), axis=1)\n",
    "VaRGranular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aead86b-7e56-4ff3-a40f-34214e10db20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Incremental VaR (Parent VAR - Parent VAR excluding self)\n",
    "\n",
    "Since pandas does not have any semantic dimension attached to its columns, it lacks the understanding of any potential hierarchical/order relationships that may lie within them, which means that implementing a measure such as incremental VaR would require us to hard code every step of that logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b34ac-64cd-4865-b361-8ff012fc7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "bookpnl=merged.groupby(['BOOK'])['PNL_VECTOR'].sum().reset_index()\n",
    "deskpnl=merged.groupby(['TRADING_DESK'])['PNL_VECTOR'].sum().reset_index()\n",
    "deskandbook=merged[['TRADING_DESK', 'BOOK']].drop_duplicates().sort_values(by=['TRADING_DESK', 'BOOK']).reset_index(drop=True)\n",
    "\n",
    "deskandbook['DESKPNL']=''\n",
    "deskandbook['BOOKPNL']=''\n",
    "\n",
    "for i in range(len(deskandbook)):\n",
    "    book=deskandbook.loc[i, 'BOOK']\n",
    "    desk=deskandbook.loc[i, 'TRADING_DESK']\n",
    "    bookpl=bookpnl[bookpnl['BOOK']==book]['PNL_VECTOR']\n",
    "    deskpl=deskpnl[deskpnl['TRADING_DESK']==desk]['PNL_VECTOR']\n",
    "    deskandbook.at[i, 'BOOKPNL']=bookpl.values\n",
    "    deskandbook.at[i, 'DESKPNL']=deskpl.values\n",
    "    \n",
    "deskandbook['DESKWITHOUTBOOK']=deskandbook['DESKPNL']-deskandbook['BOOKPNL']\n",
    "deskandbook['VaRDesk95']=deskandbook.apply(lambda x:  np.quantile(np.quantile(x['DESKPNL'], 0.05), 0.05), axis=1)\n",
    "deskandbook['VaRDeskWITHOUTBOOK95']=deskandbook.apply(lambda x: np.quantile(x['DESKWITHOUTBOOK'], 0.05), axis=1)\n",
    "\n",
    "deskandbook['IncrementalVaR']=deskandbook['VaRDesk95']-deskandbook['VaRDeskWITHOUTBOOK95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053b068-5bc3-4281-9034-746a26cd0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskandbook[[\"TRADING_DESK\", \"BOOK\", \"IncrementalVaR\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b388be4-f93d-4693-a399-73eefe236ec5",
   "metadata": {},
   "source": [
    "## What-if scenarios\n",
    "\n",
    "pandas does not support branching either, which means that the only way to create something similar to a simulation or new scenario would require loading a full new dataset in a separate data structure, not only the deltas (differing data points). This doubles the memory footprint and limits any possibility of contained, side-by-side analytics.\n",
    "\n",
    "We will start by making a copy of the original dataset, then enriching it with the stressed data points, then dropping the duplicates manually to remove the old, unstressed records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d771dc-6b14-4632-96d9-b02a63baa23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854302a6-0b3f-496f-ba00-7026e91346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition = pd.read_parquet(\n",
    "    \"data.atoti.io/notebooks/atoti-pandas-comparison/data/simulation/pnl_16.parquet\",\n",
    "    filesystem=s3,\n",
    ")\n",
    "stressed = pd.concat([stressed, addition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0815f1-791c-4f5f-bea2-a3b1efb8670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed.drop_duplicates(\n",
    "    [\"BOOKID\", \"ASOFDATE\", \"TRADEID\", \"DATASET\", \"RISKFACTOR\", \"RISKCLASS\"], keep=\"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19084d-5aa8-41c8-81af-01c647489502",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=atoti-pandas-comparison\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/Your-turn-to-try-Atoti.jpg\" alt=\"Try Atoti\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
